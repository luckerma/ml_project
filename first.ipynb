{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import joblib\n",
    "from typing import Tuple\n",
    "\n",
    "from typing import Tuple, Dict, Any\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_player_data(df, agg_funcs=None, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Aggregates player data with a prefix to distinguish home or away features.\n",
    "    \"\"\"\n",
    "    if agg_funcs is None:\n",
    "        # Default aggregation: mean for all columns except 'ID'\n",
    "        agg_funcs = {col: \"mean\" for col in df.columns if col != \"ID\"}\n",
    "    aggregated = df.groupby(\"ID\").agg(agg_funcs).reset_index()\n",
    "    if prefix:\n",
    "        aggregated = aggregated.rename(\n",
    "            columns={col: f\"{prefix}_{col}\" for col in aggregated.columns if col != \"ID\"}\n",
    "        )\n",
    "    return aggregated\n",
    "\n",
    "# Process CSV in chunks\n",
    "def process_csv_in_chunks(file_path: str, chunksize: int, drop_columns: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes a CSV file in chunks, dropping unwanted columns and handling missing columns.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "        missing_columns = [col for col in drop_columns if col not in chunk.columns]\n",
    "        if missing_columns:\n",
    "            print(f\"Warning: Missing columns {missing_columns} in {file_path}\")\n",
    "        chunk = chunk.drop(drop_columns, axis=1, errors=\"ignore\")\n",
    "        chunks.append(chunk)\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# Pre-aggregate player data in chunks and then group again by ID t\n",
    "def pre_aggregate_player_data(player_path: str, drop_columns: list[str], chunksize: int, prefix: str = \"\") -> pd.DataFrame:\n",
    "    aggregated_chunks = []\n",
    "    for chunk in pd.read_csv(player_path, chunksize=chunksize):\n",
    "        missing_columns = [col for col in drop_columns if col not in chunk.columns]\n",
    "        if missing_columns:\n",
    "            print(f\"Warning: Missing columns {missing_columns} in {player_path}\")\n",
    "        chunk = chunk.drop(drop_columns, axis=1, errors=\"ignore\")\n",
    "        aggregated_chunk = aggregate_player_data(chunk, prefix=prefix)\n",
    "        aggregated_chunks.append(aggregated_chunk)\n",
    "    # Concatenate all aggregated chunks\n",
    "    agg_all = pd.concat(aggregated_chunks, ignore_index=True)\n",
    "       agg_all = agg_all.groupby(\"ID\").mean().reset_index()\n",
    "    return agg_all\n",
    "\n",
    "# Calculate Diff and Ratio features for home and away statistics\n",
    "def calculate_diff_and_ratio(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds Diff and Ratio features for home vs away statistics.\n",
    "    Diff: home - away\n",
    "    Ratio: home / (away + 1) to avoid division by zero.\n",
    "    \"\"\"\n",
    "    for stat in [\"SHOTS_TOTAL\", \"SHOTS_ON_TARGET\", \"GOALS\", \"DANGEROUS_ATTACKS\", \"REDCARDS\", \"FOULS\"]:\n",
    "        home_stat = f\"home_{stat}_season_sum\"\n",
    "        away_stat = f\"away_{stat}_season_sum\"\n",
    "        if home_stat in df.columns and away_stat in df.columns:\n",
    "            df[f\"{stat}_DIFF\"] = df[home_stat] - df[away_stat]\n",
    "            df[f\"{stat}_RATIO\"] = df[home_stat] / (df[away_stat] + 1)\n",
    "    return df\n",
    "\n",
    "# Encode multiclass targets\n",
    "def encode_multiclass_targets(df: pd.DataFrame, cols: list) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Encodes multiclass targets based on the provided columns.\n",
    "    \"\"\"\n",
    "    arr = df[cols].values\n",
    "    return np.argmax(arr, axis=1)\n",
    "\n",
    "# Load and merge train data\n",
    "def load_and_merge_train_data(\n",
    "    home_team_path: str,\n",
    "    away_team_path: str,\n",
    "    home_players_path: str,\n",
    "    away_players_path: str,\n",
    "    target_path: str,\n",
    "    chunksize: int = 500,\n",
    ") -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    # Process team statistics with prefixes\n",
    "    df_home_team = process_csv_in_chunks(home_team_path, chunksize, drop_columns=[\"LEAGUE\", \"TEAM_NAME\"])\n",
    "    df_home_team = df_home_team.rename(columns={col: f\"home_{col}\" for col in df_home_team.columns if col != \"ID\"})\n",
    "    df_away_team = process_csv_in_chunks(away_team_path, chunksize, drop_columns=[\"LEAGUE\", \"TEAM_NAME\"])\n",
    "    df_away_team = df_away_team.rename(columns={col: f\"away_{col}\" for col in df_away_team.columns if col != \"ID\"})\n",
    "    targets = pd.read_csv(target_path)\n",
    "\n",
    "    # Pre-aggregate player data with prefixes\n",
    "    df_home_players_agg = pre_aggregate_player_data(home_players_path, [\"LEAGUE\", \"TEAM_NAME\", \"PLAYER_NAME\", \"POSITION\"], chunksize, prefix=\"home\")\n",
    "    df_away_players_agg = pre_aggregate_player_data(away_players_path, [\"LEAGUE\", \"TEAM_NAME\", \"PLAYER_NAME\", \"POSITION\"], chunksize, prefix=\"away\")\n",
    "\n",
    "    # Merge team and aggregated player data\n",
    "    merged_home = df_home_team.merge(df_home_players_agg, on=\"ID\", how=\"left\")\n",
    "    merged_away = df_away_team.merge(df_away_players_agg, on=\"ID\", how=\"left\")\n",
    "\n",
    "    # Use the home team merge as the base (the complete set of matches) and left-join the away data\n",
    "    merged_data = merged_home.merge(merged_away, on=\"ID\", how=\"left\")\n",
    "    merged_data = merged_data.merge(targets, on=\"ID\", how=\"inner\").fillna(0)\n",
    "\n",
    "    # Calculate Diff and Ratio features\n",
    "    merged_data = calculate_diff_and_ratio(merged_data)\n",
    "\n",
    "    # Encode targets and drop target and ID columns\n",
    "    y = encode_multiclass_targets(merged_data, [\"HOME_WINS\", \"DRAW\", \"AWAY_WINS\"])\n",
    "    merged_data.drop([\"HOME_WINS\", \"DRAW\", \"AWAY_WINS\", \"ID\"], axis=1, inplace=True)\n",
    "    return merged_data, y\n",
    "\n",
    "# Load and merge test data using pre-aggregation\n",
    "def load_and_merge_test_data_chunked(\n",
    "    home_team_test_path: str,\n",
    "    away_team_test_path: str,\n",
    "    home_players_test_path: str,\n",
    "    away_players_test_path: str,\n",
    "    chunksize: int = 1000,\n",
    ") -> pd.DataFrame:\n",
    "    # Process team data with prefixes\n",
    "    df_home_team = process_csv_in_chunks(home_team_test_path, chunksize, drop_columns=[\"LEAGUE\", \"TEAM_NAME\"])\n",
    "    df_home_team = df_home_team.rename(columns={col: f\"home_{col}\" for col in df_home_team.columns if col != \"ID\"})\n",
    "    df_away_team = process_csv_in_chunks(away_team_test_path, chunksize, drop_columns=[\"LEAGUE\", \"TEAM_NAME\"])\n",
    "    df_away_team = df_away_team.rename(columns={col: f\"away_{col}\" for col in df_away_team.columns if col != \"ID\"})\n",
    "    \n",
    "    print(f\"Processed team data: Home team -> {df_home_team.shape}, Away team -> {df_away_team.shape}\")\n",
    "    \n",
    "    # Pre-aggregate player data with prefixes\n",
    "    df_home_players_agg = pre_aggregate_player_data(\n",
    "        home_players_test_path, \n",
    "        drop_columns=[\"LEAGUE\", \"TEAM_NAME\", \"PLAYER_NAME\", \"POSITION\"], \n",
    "        chunksize=chunksize, \n",
    "        prefix=\"home\"\n",
    "    )\n",
    "    df_away_players_agg = pre_aggregate_player_data(\n",
    "        away_players_test_path, \n",
    "        drop_columns=[\"LEAGUE\", \"TEAM_NAME\", \"PLAYER_NAME\", \"POSITION\"], \n",
    "        chunksize=chunksize, \n",
    "        prefix=\"away\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Pre-aggregated player data: Home players -> {df_home_players_agg.shape}, Away players -> {df_away_players_agg.shape}\")\n",
    "    \n",
    "    # Merge team data with the aggregated player data (using home team as base)\n",
    "    merged_home = df_home_team.merge(df_home_players_agg, on=\"ID\", how=\"left\")\n",
    "    print(f\"Merged home shape -> {merged_home.shape}\")\n",
    "    \n",
    "    merged_away = df_away_team.merge(df_away_players_agg, on=\"ID\", how=\"left\")\n",
    "    print(f\"Merged away shape -> {merged_away.shape}\")\n",
    "    \n",
    "   \n",
    "    merged_test = merged_home.merge(merged_away, on=\"ID\", how=\"left\")\n",
    "    print(f\"Final merged test data shape -> {merged_test.shape}\")\n",
    "    \n",
    "    return merged_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home_team_csv = \"data/Train_Data/train_home_team_statistics_df.csv\"\n",
    "train_away_team_csv = \"data/Train_Data/train_away_team_statistics_df.csv\"\n",
    "train_home_players_csv = \"data/Train_Data/train_home_player_statistics_df.csv\"\n",
    "train_away_players_csv = \"data/Train_Data/train_away_player_statistics_df.csv\"\n",
    "y_csv = \"data/Y_train_1rknArQ.csv\"\n",
    "\n",
    "X_raw, y_raw = load_and_merge_train_data(\n",
    "  train_home_team_csv,\n",
    "  train_away_team_csv,\n",
    "  train_home_players_csv,\n",
    "  train_away_players_csv,\n",
    "  y_csv\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Shape of training data:\", X_raw.shape)\n",
    "print(\"Unique target classes:\", np.unique(y_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary stats:\")\n",
    "display(X_raw.describe().T.head(10))\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "class_counts = pd.Series(y_raw).value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "sns.countplot(x=y_raw)\n",
    "plt.title(\"Distribution of Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a random sample to reduce computation during grid search.\n",
    "sample_frac = 0.05  \n",
    "X_sample = X_raw.sample(frac=sample_frac, random_state=42)\n",
    "y_sample = y_raw[X_sample.index]\n",
    "\n",
    "print(\"Shape of sampled data for tuning:\", X_sample.shape)\n",
    "\n",
    "#Train/Test Split on Sample for Tuning\n",
    "X_train_s, X_val_s, y_train_s, y_val_s = train_test_split(\n",
    "  X_sample, \n",
    "  y_sample, \n",
    "  test_size=0.2, \n",
    "  random_state=42, \n",
    "  stratify=y_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models and Parameter Grids with n_jobs=-1\n",
    "models = {\n",
    "  \"LogisticRegression\": {\n",
    "    \"estimator\": LogisticRegression(max_iter=2000, solver=\"lbfgs\", n_jobs=-1),\n",
    "    \"param_grid\": {\"C\": [0.01, 0.1, 1.0], \"penalty\": [\"l2\"]}\n",
    "  },\n",
    "  \"RandomForest\": {\n",
    "    \"estimator\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    \"param_grid\": {\"n_estimators\": [50, 100], \"max_depth\": [3, 6]}\n",
    "  },\n",
    "  \"XGBClassifier\": {\n",
    "    \"estimator\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\", n_jobs=-1),\n",
    "    \"param_grid\": {\"n_estimators\": [50, 100], \"max_depth\": [3, 6], \"learning_rate\": [0.1, 0.01]}\n",
    "  }\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, cfg in models.items():\n",
    "  print(f\"Tuning {name} ...\")\n",
    "  clf = cfg[\"estimator\"]\n",
    "  param_grid = cfg[\"param_grid\"]\n",
    "  grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    "  )\n",
    "  grid.fit(X_train_s, y_train_s)\n",
    "  best_model = grid.best_estimator_\n",
    "  val_preds = best_model.predict(X_val_s)\n",
    "  acc = accuracy_score(y_val_s, val_preds)\n",
    "  f1 = f1_score(y_val_s, val_preds, average=\"macro\")\n",
    "  \n",
    "  results[name] = {\n",
    "    \"best_params\": grid.best_params_,\n",
    "    \"accuracy\": acc,\n",
    "    \"f1_score\": f1,\n",
    "    \"best_estimator\": best_model\n",
    "  }\n",
    "  \n",
    "  print(f\"{name} tuned. Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Tuning Results from Sample\n",
    "comparison = pd.DataFrame(\n",
    "  [\n",
    "    [mn, md[\"accuracy\"], md[\"f1_score\"], md[\"best_params\"]]\n",
    "    for mn, md in results.items()\n",
    "  ],\n",
    "  columns=[\"Model\", \"Accuracy\", \"F1 Score\", \"Best Params\"]\n",
    ")\n",
    "print(\"Tuning Results on Sample Data:\")\n",
    "display(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model from the sample data to train on the full data.\n",
    "best_model_name = max(results, key=lambda k: results[k][\"accuracy\"])\n",
    "best_params = results[best_model_name][\"best_params\"]\n",
    "print(\"Best model on sample:\", best_model_name, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_name == \"LogisticRegression\":\n",
    "  final_model = LogisticRegression(max_iter=2000, solver=\"lbfgs\", n_jobs=-1, **best_params)\n",
    "elif best_model_name == \"RandomForest\":\n",
    "  final_model = RandomForestClassifier(random_state=42, n_jobs=-1, **best_params)\n",
    "elif best_model_name == \"XGBClassifier\":\n",
    "  final_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\", n_jobs=-1, **best_params)\n",
    "  \n",
    "X_train_full, X_val_full, y_train_full, y_val_full = train_test_split(\n",
    "  X_raw, y_raw, test_size=0.2, random_state=42, stratify=y_raw\n",
    ")\n",
    "\n",
    "print(\"Training final model on full data...\")\n",
    "final_model.fit(X_train_full, y_train_full)\n",
    "final_preds = final_model.predict(X_val_full)\n",
    "print(\"Full Data Accuracy:\", accuracy_score(y_val_full, final_preds))\n",
    "print(\"Full Data F1 Score:\", f1_score(y_val_full, final_preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "import joblib\n",
    "joblib.dump(final_model, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the final model\n",
    "cm = confusion_matrix(y_val_full, final_preds)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix - {best_model_name}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report for Final Model:\")\n",
    "print(classification_report(y_val_full, final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "final_model = joblib.load(\"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_home_team_csv = \"data/Test_Data/test_home_team_statistics_df.csv\"\n",
    "test_away_team_csv = \"data/Test_Data/test_away_team_statistics_df.csv\"\n",
    "test_home_players_csv = \"data/Test_Data/test_home_player_statistics_df.csv\"\n",
    "test_away_players_csv = \"data/Test_Data/test_away_player_statistics_df.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load test data using the chunked processing function\n",
    "X_test = load_and_merge_test_data_chunked(\n",
    "  test_home_team_csv,\n",
    "  test_away_team_csv,\n",
    "  test_home_players_csv,\n",
    "  test_away_players_csv\n",
    ")\n",
    "\n",
    "print(\"Shape of test data:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the merged test data still contains the \"ID\" column, aggregate it so that each unique ID appears once.\n",
    "if \"ID\" in X_test.columns:\n",
    "    before = X_test.shape[0]\n",
    "    X_test = X_test.drop_duplicates(subset=\"ID\")\n",
    "    after = X_test.shape[0]\n",
    "    print(f\"Reduced rows from {before} to {after} by grouping over ID.\")\n",
    "    test_ids = X_test[\"ID\"].values\n",
    "    X_test = X_test.drop(\"ID\", axis=1)\n",
    "else:\n",
    "    test_ids = X_test.index.values\n",
    "\n",
    "print(\"Extracted test IDs with shape:\", test_ids.shape)\n",
    "\n",
    "# Predict labels on the test data using final_model.\n",
    "predicted_labels = final_model.predict(X_test)\n",
    "\n",
    "# Convert predicted class labels to one-hot encoding.\n",
    "mapping = {0: [1, 0, 0], 1: [0, 1, 0], 2: [0, 0, 1]}\n",
    "submission_data = [[id_, *mapping[label]] for id_, label in zip(test_ids, predicted_labels)]\n",
    "\n",
    "# Create submission DataFrame with the required column names.\n",
    "submission = pd.DataFrame(submission_data, columns=[\"ID\", \"HOME_WINS\", \"DRAW\", \"AWAY_WINS\"])\n",
    "\n",
    "# Write to CSV file.\n",
    "submission.to_csv(\"final_submission.csv\", index=False)\n",
    "print(\"Submission file created: final_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
